{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csc_matrix\n",
    "data = sio.loadmat('XwindowsDocData.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = data['xtrain']; xtest = data['xtest']\n",
    "ytrain = data['ytrain']; ytest = data['ytest']\n",
    "vocab = data['vocab']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifiers\n",
    "- To classify vectors of discrete-valued features, $\\mathbf{x}\\in\\{1,...,K\\}^D$, where K is the number of values for each feature, and D is the number of features. A generative approach requires to specify the class conditional distribution, $p(\\mathbf{x}|y=c)$. The simplest approach is to assume the features are conditionally independent given the class label. The class conditional density as a product of one dimensional densities: \n",
    "\n",
    "$$p(\\mathbf{x}|y=c,\\mathbf{\\theta})= \\prod^D_{j=1}p(x_j|y=c,\\theta_{jc})$$\n",
    "\n",
    "The resulting model is called a naive Bayes classifier (NBC) $\\sim O(CD)$, for C classes and D features.\n",
    "\n",
    "- In the case of **real-valued features**, the Gaussian distribution can be used. $p(\\mathbf{x}|y=c,\\theta)=\\prod^D_{j=1}\\mathcal{N}(x_j|\\mu_{jc},\\sigma^2_{jc})$, where $\\mu_{jc}$ the mean of feature $j$ in objects of class $c$, and $\\sigma^2_{jc}$ its variance.\n",
    "- In the case of **binary features**, $x_j\\in\\{0,1\\}$, the Bernoulli distribution $p(\\mathbf{x}|y=c,\\theta)=\\prod^D_{j=1}Ber(x_j|\\mu_{jc})$, where $\\mu_{jc}$ the probability that feature $j$ occurs in class $c$. (**multivariate Bernoulli naive Bayes**)\n",
    "- In the case of **categorical features**, $x_j\\in\\{1,...,K\\}$, the multinoulli distribution is used, $p(\\mathbf{x}|y=c,\\theta)=\\prod^D_{j=1}Cat(x_j|\\mu_{jc})$, where $\\mu_{jc}$ is a histogram over the K possible values for x_j in class c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a naive Bayes classifier = computing the MLE or the MAP estimate for the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLE for NBC\n",
    "The probability for a single data case is given by,\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x_i},y_i|\\theta) = p(y_i|\\pi)\\prod_j p(x_{ij}|\\theta_j) = \\prod_c \\pi_c^{\\mathbb{I}(y_i=c)}\\prod_j\\prod_c p(x_{ij}|\\theta_{jc})^{\\mathbb{I}(y_i=c)}\n",
    "$$\n",
    "\n",
    "where $p(y_i|\\pi)$ the likelihood over a class $c$, and $p(x_{ij}|\\theta_j)$ the probability of feature $j$ in the text document $i$ over class $c$. \n",
    "\n",
    "\\begin{align}\n",
    "\\log p(\\mathcal{D}|\\theta) &= \\sum_i\\log p(\\mathbf{x}_i,y_i|\\theta) = \\sum_i\\log\\prod_c \\pi_c^{\\mathbb{I}(y_i=c)}\\prod_j\\prod_c p(x_{ij}|\\theta_{jc})^{\\mathbb{I}(y_i=c)} \\\\\n",
    "&= \\sum_i\\sum^C_{c=1}\\mathbb{I}(y_i=c)\\log\\pi_c+\\sum_i\\sum_{j=1}^D\\sum^C_{c=1}\\mathbb{I}(y_i=c)\\log p(x_{ij}|\\theta_{jc}) \\\\\n",
    "\\log p(\\mathcal{D}|\\theta) &= \\sum^C_{c=1}N_c\\log\\pi_c + \\sum_{j=1}^D\\sum^C_{c=1}\\sum_{i:y_i=c}\\log p(x_{ij}|\\theta_{jc})\n",
    "\\end{align}\n",
    "\n",
    "where $N_c\\triangleq\\sum_i\\mathbb{I}(y_i=c)$ is the number of examples in class c.\n",
    "\n",
    "To enforce the constraints that $\\sum_c\\pi_c = 1$, a **Lagrange multiplier** is used. The **constrained objective function (Lagrangian)** is given by the **log likelihood** + the **constraint**: \n",
    "\n",
    "$$\\mathcal{l}(\\theta,\\lambda) = \\sum^C_{c=1}N_c\\log\\pi_c + \\sum_{j=1}^D\\sum^C_{c=1}\\sum_{i:y_i=c}\\log p(x_{ij}|\\theta_{jc})+\\lambda(1-\\sum_c\\pi_c)$$\n",
    "\n",
    "Taking derivatives with respect to $\\lambda$ yields the original constraint $\\sum_c\\pi_c = 1$. \n",
    "\n",
    "Taking derivatives with respect to $\\pi_c$ yields\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{l}}{\\partial \\pi_c} &= \\frac{N_c}{\\pi_c}-\\lambda =0 \\Longrightarrow N_c = \\lambda\\pi_c \\\\\n",
    "\\Longrightarrow \\sum_c N_c &= \\lambda\\sum_c\\pi_c \\Longrightarrow\n",
    "\\lambda = \\sum_c N_c = N\n",
    "\\end{align}\n",
    "Therefore, $$\\hat{\\pi}_c = \\frac{N_c}{\\lambda}=\\frac{N_c}{N}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying documents using bag of words\n",
    "**Document classification** is the problem of classifying text documents into different categories. One simple approach is to represent each document as a binary vector, which records whether each word is present or not, so $x_{ij}=1$ iff (if or only if) word $j$ occurs in document $i$, otherwise $x_{ij}=0$.\n",
    "Suppose all features are binary (sparse matrix), so $x_i|y = c \\sim Ber(\\theta_{jc})$ and $p(x_{ij}|\\theta_{jc}) = Ber(x_{ij}|\\theta_{jc}) = \\theta_{jc}^{\\mathbb{I}(x_{ij})}(1-\\theta_{jc})^{\\mathbb{I}(1-x_{ij})}$.\n",
    "\n",
    "Class conditional density:\n",
    "$$p(\\mathbf{x}_i|y_i=c,\\theta)=\\prod^D_{j=1}Ber(x_{ij}|\\theta_{jc})=\\prod^D_{j=1}\\theta_{jc}^{\\mathbb{I}(x_{ij})}(1-\\theta_{jc})^{\\mathbb{I}(1-x_{ij})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enforce the constraints that $\\sum_c\\sum_j\\theta_{jc} = 1$, a **Lagrange multiplier** is used. The **constrained objective function (Lagrangian)** is given by the **log likelihood** + the **constraint**: \n",
    "\n",
    "$$\\mathcal{l}(\\theta,\\lambda) = \\sum^C_{c=1}N_c\\log\\pi_c + \\sum_{j=1}^D\\sum^C_{c=1}\\sum_{i:y_i=c}\\log p(x_{ij}|\\theta_{jc})+\\lambda(1-\\sum_j\\sum_c\\theta_{jc})$$\n",
    "\n",
    "Therefore, $$\\hat{\\theta}_{jc}=\\frac{N_{jc}}{N}$$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a naive Bayes classifier to binary features\n",
    "$$\\hat{\\pi}_c= \\frac{N_c}{N}\\text{ , }\\hat{\\theta}_{jc}=\\frac{N_{jc}}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesFit(xtrain,ytrain):\n",
    "    pC = 1\n",
    "    c = np.unique(ytrain)\n",
    "    Ntrain,D = xtrain.shape\n",
    "    theta = np.zeros((len(c),D))\n",
    "    Nclass = []\n",
    "    for i in c:\n",
    "        ndx = np.where(ytrain==i)[0]\n",
    "        Xtr = xtrain[ndx,:]\n",
    "        Non = np.sum(Xtr==1,axis=0)\n",
    "        Noff = np.sum(Xtr==0,axis=0)\n",
    "        theta[i-1,:] = (Non+pC)/(Non+Noff+2*pC)\n",
    "        Nclass.append(len(ndx))\n",
    "    classPrior = Nclass/np.sum(Nclass)\n",
    "    return theta,classPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\44754\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SparseEfficiencyWarning: Comparing a sparse matrix with 0 using == is inefficient, try using != instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\44754\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SparseEfficiencyWarning: Comparing a sparse matrix with 0 using == is inefficient, try using != instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "theta,classPrior = naiveBayesFit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with a naive bayes classifier for binary features\n",
    "\n",
    "$$p(y=c|\\mathbf{x},\\mathcal{D})\\propto p(y=c|\\mathcal{D})\\prod^D_{j=1}p(x_j|y=c,\\mathcal{D})$$\n",
    "\n",
    "The correct Bayesian procedure is to integrate out the unknwon parameters,\n",
    "\n",
    "$$p(y=c|\\mathbf{x},\\mathcal{D})\\propto\\bigg[\\int Cat(y=c|\\pi)p(\\pi|\\mathcal{D})d\\pi\\bigg]\\prod^D_{j=1}\\int Ber(x_j|y=c,\\theta_{jc})p(\\theta_{jc}|\\mathcal{D})$$\n",
    "\n",
    "The posterior predictive density is given by,\n",
    "\n",
    "\\begin{align}\n",
    "p(y=c|\\mathbf{x},\\mathcal{D})&\\propto \\bar{\\pi}_c\\prod^D_{j=1}\\bar{\\theta}_{jc}^{\\mathbb{I}(x_j=1)}(1-\\bar{\\theta}_{jc})^{\\mathbb{I}(x_j=0)} \\\\\n",
    "\\bar{\\theta}_{jk} &= \\frac{N_{jc}+\\beta_1}{N_c+\\beta_0+\\beta_1} \\\\\n",
    "\\bar{\\pi}_c &= \\frac{N_c+\\alpha_c}{N+\\alpha_0}\n",
    "\\end{align}\n",
    "\n",
    "To avoid numerical underflow, the log-sum-exp trick is also used. \n",
    "\n",
    "\\begin{align}\n",
    "p_{ic} &= \\exp(L_{ic}-\\log\\sum\\exp L_{i,:}) \\\\\n",
    "\\hat{y}_i &= \\arg\\max_c p_{ic}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesPredict(theta,classPrior,xtest):\n",
    "    Ntest = xtest.shape[0]\n",
    "    C = theta.shape[0]\n",
    "    logPrior = np.log(classPrior)\n",
    "    logPost = np.zeros((Ntest,C))\n",
    "    #logPost = []\n",
    "    logT = np.log(theta)\n",
    "    logTnot = np.log(1-theta)\n",
    "    xtestnot = csc_matrix((xtest.todense()==0)*1)\n",
    "\n",
    "    xtesttmp = xtest.todense()\n",
    "    xtestnottmp = xtestnot.todense()\n",
    "    for i in np.array([1,2]):\n",
    "        tmpT = np.tile(logT[i-1,:],(Ntest,1))\n",
    "        tmpTnot = np.tile(logTnot[i-1,:],(Ntest,1))\n",
    "        L1 = csc_matrix(np.multiply(tmpT,xtesttmp))\n",
    "        L0 = csc_matrix(np.multiply(tmpTnot,xtestnottmp))\n",
    "        logPost[:,i-1]=np.sum(L0+L1,axis=1).squeeze()\n",
    "    yhat = np.argmax(logPost,axis=1)\n",
    "    return yhat\n",
    "def zeroOneLossFn(y,ypred):\n",
    "    err = y!=ypred\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_train = naiveBayesPredict(theta,classPrior,xtrain)\n",
    "err_train = np.mean(zeroOneLossFn(ytrain.squeeze(),ypred_train+1))\n",
    "ypred_test = naiveBayesPredict(theta,classPrior,xtest)\n",
    "err_test = np.mean(zeroOneLossFn(ytest.squeeze(),ypred_test+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification rate on train: 0.08333333333333333\n",
      "Misclassification rate on test: 0.18666666666666668\n"
     ]
    }
   ],
   "source": [
    "print('Misclassification rate on train: '+str(err_train))\n",
    "print('Misclassification rate on test: '+str(err_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 600 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(theta[0,:].shape[0]),theta[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 600 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(theta[1,:].shape[0]),theta[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
