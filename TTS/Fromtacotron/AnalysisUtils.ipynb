{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvfileDIR = 'D:/44754/Documents/Data/LJSpeech-1.1/wavs/LJ001-0008.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "    '''Hyper parameters'''\n",
    "    # pipeline\n",
    "    prepro = False  # if True, run `python prepro.py` first before running `python train.py`.\n",
    "    vocab = \"PE abcdefghijklmnopqrstuvwxyz'.?\" # P: Padding E: End of Sentence\n",
    "    # data\n",
    "    data = \"/data/private/voice/LJSpeech-1.0\"\n",
    "    # data = \"/data/private/voice/nick\"\n",
    "    test_data = 'harvard_sentences.txt'\n",
    "    max_duration = 10.0\n",
    "\n",
    "    # signal processing\n",
    "    sr = 22050 # Sample rate.\n",
    "    n_fft = 2048 # fft points (samples)\n",
    "    frame_shift = 0.0125 # seconds\n",
    "    frame_length = 0.05 # seconds\n",
    "    hop_length = int(sr*frame_shift) # samples.\n",
    "    win_length = int(sr*frame_length) # samples.\n",
    "    n_mels = 80 # Number of Mel banks to generate\n",
    "    power = 1.2 # Exponent for amplifying the predicted magnitude\n",
    "    n_iter = 50 # Number of inversion iterations\n",
    "    preemphasis = .97 # or None\n",
    "    max_db = 100\n",
    "    ref_db = 20\n",
    "\n",
    "    # model\n",
    "    embed_size = 256 # alias = E\n",
    "    encoder_num_banks = 16\n",
    "    decoder_num_banks = 8\n",
    "    num_highwaynet_blocks = 4\n",
    "    r = 5 # Reduction factor. Paper => 2, 3, 5\n",
    "    dropout_rate = .5\n",
    "\n",
    "    # training scheme\n",
    "    lr = 0.001 # Initial learning rate.\n",
    "    logdir = \"logdir/01\"\n",
    "    sampledir = 'samples'\n",
    "    batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrograms(fpath):\n",
    "    hp = Hyperparams\n",
    "    '''Returns normalized log(melspectrogram) and log(magnitude) from `sound_file`.\n",
    "    Args:\n",
    "      sound_file: A string. The full path of a sound file.\n",
    "    Returns:\n",
    "      mel: A 2d array of shape (T, n_mels) <- Transposed\n",
    "      mag: A 2d array of shape (T, 1+n_fft/2) <- Transposed\n",
    "    '''\n",
    "    # Loading sound file\n",
    "    y, sr = librosa.load(fpath, sr=hp.sr)\n",
    "    # Trimming\n",
    "    y, _ = librosa.effects.trim(y)\n",
    "    # Preemphasis\n",
    "    y = np.append(y[0], y[1:] - hp.preemphasis * y[:-1])\n",
    "    # stft\n",
    "    linear = librosa.stft(y=y,\n",
    "                          n_fft=hp.n_fft,\n",
    "                          hop_length=hp.hop_length,\n",
    "                          win_length=hp.win_length)\n",
    "    # magnitude spectrogram\n",
    "    mag = np.abs(linear)  # (1+n_fft//2, T)\n",
    "    # mel spectrogram\n",
    "    mel_basis = librosa.filters.mel(hp.sr, hp.n_fft, hp.n_mels)  # (n_mels, 1+n_fft//2)\n",
    "    mel = np.dot(mel_basis, mag)  # (n_mels, t)\n",
    "    # to decibel\n",
    "    mel = 20 * np.log10(np.maximum(1e-5, mel))\n",
    "    mag = 20 * np.log10(np.maximum(1e-5, mag))\n",
    "    # normalize\n",
    "    mel = np.clip((mel - hp.ref_db + hp.max_db) / hp.max_db, 1e-8, 1)\n",
    "    mag = np.clip((mag - hp.ref_db + hp.max_db) / hp.max_db, 1e-8, 1)\n",
    "    # Transpose\n",
    "    mel = mel.T.astype(np.float32)  # (T, n_mels)\n",
    "    mag = mag.T.astype(np.float32)  # (T, 1+n_fft//2)\n",
    "\n",
    "    return mel, mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel,mag = get_spectrograms(wvfileDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 80) (144, 1025)\n"
     ]
    }
   ],
   "source": [
    "print(mel.shape,mag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
